{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0446ac2",
   "metadata": {},
   "source": [
    "# Импортируем библиотеки\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "id": "81340d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.models import Pooling, Transformer\n",
    "\n",
    "import uuid\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, PointStruct\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "import optuna\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecdb90c",
   "metadata": {},
   "source": [
    "Чтение и преобразование размеченных данных в pandas-таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "id": "62ef9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_files = 'gemini_predicted_data/'\n",
    "file_list = glob.glob(path_to_files + \"gemini_preds_*.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "id": "bf2d6410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gemini_predicted_data\\\\gemini_preds_1925.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_389.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_400.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_700.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_705.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_720.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_735.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_750.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_765.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_780.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_795.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_810.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_825.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_840.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_855.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_870.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_885.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_900.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_915.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_930.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_945.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_960.pickle',\n",
       " 'gemini_predicted_data\\\\gemini_preds_from700_990.pickle']"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "id": "ee63aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for file in file_list:\n",
    "    with open(file, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    \n",
    "    temp_df = pd.DataFrame(data=data)\n",
    "    df = pd.concat([df, temp_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "id": "b45e4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['text', 'gigachat_preds']).rename(columns={'gigachat_preds': 'gemini_preds'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bc8c99",
   "metadata": {},
   "source": [
    "Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "id": "f9e7c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_surrounding_newlines_and_backticks(text):\n",
    "    \"\"\"\n",
    "    Проверяет, начинается ли строка с \"\\n```\" и заканчивается ли на \"\\n```\",\n",
    "    и если да, удаляет эти последовательности.\n",
    "\n",
    "    Args:\n",
    "        text (str): Входная строка.\n",
    "\n",
    "    Returns:\n",
    "        str: Строка с удаленными начальными и конечными \"\\n```\", \n",
    "             если они присутствовали.\n",
    "    \"\"\"\n",
    "    start_sequence = \"```\\n\"\n",
    "    end_sequence = \"\\n```\"\n",
    "    \n",
    "    second_start_sequence = \"```json\"\n",
    "    second_end_sequence = \"```\"\n",
    "    \n",
    "    if text.startswith(start_sequence) and text.endswith(end_sequence):\n",
    "        return text[len(start_sequence):-len(end_sequence)]\n",
    "    elif text.startswith(second_start_sequence) and text.endswith(second_end_sequence):\n",
    "        return text[len(second_start_sequence):-len(second_end_sequence)]\n",
    "    \n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "id": "091ec7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_newlines_and_trailing_spaces(text):\n",
    "    \"\"\"\n",
    "    Удаляет все символы новой строки (\"\\n\") и пробелы в конце строки.\n",
    "\n",
    "    Args:\n",
    "        text (str): Входная строка.\n",
    "\n",
    "    Returns:\n",
    "        str: Строка без символов новой строки и пробелов в конце.\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \"\")  # Удаляем символы новой строки\n",
    "    return text.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "id": "20e31cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values_from_json_strings(df, column_name):\n",
    "    \"\"\"\n",
    "    Извлекает значения из JSON-строк в указанном столбце DataFrame\n",
    "    и создает новые колонки для каждого ключа.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame с JSON-строками.\n",
    "        column_name (str): Название столбца с JSON-строками.\n",
    "    \"\"\"\n",
    "    def parse_json_string(text):\n",
    "        try:\n",
    "            text = text.replace(\"'\", '\"')  # Заменяем одинарные кавычки на двойные\n",
    "            data = json.loads(text)\n",
    "            return data.get('prediction'), data.get('agitation'), data.get('emotions'), data.get('politics')\n",
    "        except json.JSONDecodeError:\n",
    "            return None, None, None, None\n",
    "        \n",
    "    df[['prediction', 'agitation', 'emotions', 'politics']] = df[column_name].apply(parse_json_string).apply(pd.Series)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "id": "7d4c5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_to_string(text_list):\n",
    "    if text_list:  # Проверить, не пустой ли список\n",
    "        return ' '.join(text_list)\n",
    "    else:\n",
    "        return ''  # Вернуть пустую строку для пустых списков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "id": "bc56e91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['gemini_preds'] = df['gemini_preds'].apply(remove_surrounding_newlines_and_backticks)\n",
    "df['gemini_preds'] = df['gemini_preds'].apply(remove_all_newlines_and_trailing_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "id": "277359d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 297 ms\n",
      "Wall time: 284 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = extract_values_from_json_strings(df, 'gemini_preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "id": "91060ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "id": "4a7a1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['agitation'] = data['agitation'].apply(convert_list_to_string)\n",
    "data['emotions'] = data['emotions'].apply(convert_list_to_string)\n",
    "data['politics'] = data['politics'].apply(convert_list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "id": "c6eda0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>gemini_preds</th>\n",
       "      <th>index</th>\n",
       "      <th>prediction</th>\n",
       "      <th>agitation</th>\n",
       "      <th>emotions</th>\n",
       "      <th>politics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>кб двухбуквенная аббревиатура наиболее вероятн...</td>\n",
       "      <td>{'prediction': 1, 'agitation': [], 'emotions':...</td>\n",
       "      <td>999</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>марина орлова орлова марина викторовна российс...</td>\n",
       "      <td>{'prediction': 1, 'agitation': [], 'emotions':...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>золотая серп и молот ссср учреждена указом пре...</td>\n",
       "      <td>{'prediction': 1, 'agitation': [], 'emotions':...</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>тбилиси страны стран участников спортсмен меда...</td>\n",
       "      <td>{'prediction': 1, 'agitation': [], 'emotions':...</td>\n",
       "      <td>1002</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>портрет п а столыпина картина ильи репина напи...</td>\n",
       "      <td>{'prediction': 1, 'agitation': [], 'emotions':...</td>\n",
       "      <td>1003</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>город в регион нет поселения поселение поселен...</td>\n",
       "      <td>{'prediction': 0, 'agitation': [], 'emotions':...</td>\n",
       "      <td>984</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>великолепный мягкие</td>\n",
       "      <td>советская власть гражданская война белая армия...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>крестовые походы религиозные военные экспедици...</td>\n",
       "      <td>{'prediction': 1, 'agitation': [], 'emotions':...</td>\n",
       "      <td>985</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>флага герб герба страна испания региона автоно...</td>\n",
       "      <td>{'prediction': 1, 'agitation': [], 'emotions':...</td>\n",
       "      <td>986</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>сингл третий сингл эминема с альбома альбом вт...</td>\n",
       "      <td>{'prediction': 1, 'agitation': [], 'emotions':...</td>\n",
       "      <td>988</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>шинель одна из петербургских повестей русского...</td>\n",
       "      <td>{'prediction': 1, 'agitation': [], 'emotions':...</td>\n",
       "      <td>989</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>любимая шинель прекрасном расположении духа с ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1813 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     кб двухбуквенная аббревиатура наиболее вероятн...   \n",
       "1     марина орлова орлова марина викторовна российс...   \n",
       "2     золотая серп и молот ссср учреждена указом пре...   \n",
       "3     тбилиси страны стран участников спортсмен меда...   \n",
       "4     портрет п а столыпина картина ильи репина напи...   \n",
       "...                                                 ...   \n",
       "1808  город в регион нет поселения поселение поселен...   \n",
       "1809  крестовые походы религиозные военные экспедици...   \n",
       "1810  флага герб герба страна испания региона автоно...   \n",
       "1811  сингл третий сингл эминема с альбома альбом вт...   \n",
       "1812  шинель одна из петербургских повестей русского...   \n",
       "\n",
       "                                           gemini_preds  index  prediction  \\\n",
       "0     {'prediction': 1, 'agitation': [], 'emotions':...    999         1.0   \n",
       "1     {'prediction': 1, 'agitation': [], 'emotions':...   1000         1.0   \n",
       "2     {'prediction': 1, 'agitation': [], 'emotions':...   1001         1.0   \n",
       "3     {'prediction': 1, 'agitation': [], 'emotions':...   1002         1.0   \n",
       "4     {'prediction': 1, 'agitation': [], 'emotions':...   1003         1.0   \n",
       "...                                                 ...    ...         ...   \n",
       "1808  {'prediction': 0, 'agitation': [], 'emotions':...    984         0.0   \n",
       "1809  {'prediction': 1, 'agitation': [], 'emotions':...    985         1.0   \n",
       "1810  {'prediction': 1, 'agitation': [], 'emotions':...    986         1.0   \n",
       "1811  {'prediction': 1, 'agitation': [], 'emotions':...    988         1.0   \n",
       "1812  {'prediction': 1, 'agitation': [], 'emotions':...    989         1.0   \n",
       "\n",
       "     agitation                                           emotions  \\\n",
       "0                                                                   \n",
       "1                                                                   \n",
       "2                                                                   \n",
       "3                                                                   \n",
       "4                                                                   \n",
       "...        ...                                                ...   \n",
       "1808                                          великолепный мягкие   \n",
       "1809                                                                \n",
       "1810                                                                \n",
       "1811                                                                \n",
       "1812            любимая шинель прекрасном расположении духа с ...   \n",
       "\n",
       "                                               politics  \n",
       "0                                                        \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "...                                                 ...  \n",
       "1808  советская власть гражданская война белая армия...  \n",
       "1809                                                     \n",
       "1810                                                     \n",
       "1811                                                     \n",
       "1812                                                     \n",
       "\n",
       "[1813 rows x 7 columns]"
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "id": "d60a74ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1496\n",
       "0.0     310\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.prediction.value_counts() # число записей для каждого класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "id": "417ac43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.prediction.isna()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "id": "b3683763",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.prediction = data.prediction.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd151f",
   "metadata": {},
   "source": [
    "# Готовим данные для векторной БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "fe0f9f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#дополнительные данные для разделов \"политика\" и \"эмоции\"\n",
    "with open('emotional_data_list.pickle', 'rb') as file:\n",
    "    politics_list = pickle.load(file)\n",
    "    \n",
    "with open('emotional_words_list.pickle', 'rb') as file:\n",
    "    emotions_list = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "c81ffb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_list = politics_list[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "id": "2139309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_list = emotions_list[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "id": "a07721a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_list_string = ' '.join(politics_list)\n",
    "emotions_list_string = ' '.join(emotions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "id": "8495db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_columnText_into_string(df: pd.DataFrame, column_name: str):\n",
    "    df[column_name] = df[column_name].astype(str)\n",
    "    merged_string = \" \".join(df[column_name].tolist())\n",
    "    \n",
    "    return merged_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "id": "9d57ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_chunks(text: str, sep, chunk_size: int, chunk_overlap: int):\n",
    "    # Разбиваем текст на чанки\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators = sep, # разделитель, в нашем случае - пробел ' '\n",
    "        chunk_size = chunk_size, # размер чанка\n",
    "        chunk_overlap = chunk_overlap, # наслаивание чанков. Например, первый чанк - от 0 до 100 символа, 2 чанк от 80 до 180. Наслаивание - 20\n",
    "        length_function = len,\n",
    "        is_separator_regex = False,\n",
    "        add_start_index = False\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "id": "1712d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_emotions_string = merge_columnText_into_string(data, 'emotions') #объединяем найденные слова-маркеры в одну строку\n",
    "merged_agitation_string = merge_columnText_into_string(data, 'agitation')\n",
    "merged_politics_string = merge_columnText_into_string(data, 'politics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "id": "59992968",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_string_PAE = ' '.join([merged_emotions_string, merged_agitation_string, merged_politics_string, emotions_list_string, politics_list_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "id": "e8da52fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111827"
      ]
     },
     "execution_count": 1000,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_string_PAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "id": "d1610c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_extra_spaces(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "id": "c27ccf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_string_PAE = delete_extra_spaces(merged_string_PAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "id": "20085167",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_length = list()\n",
    "for token in merged_string_PAE.split(' '):\n",
    "    token_length.append(len(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "id": "55a6dff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя длина слова из конкатенированной строки: 8.211571526822558\n"
     ]
    }
   ],
   "source": [
    "print(f'Средняя длина слова из конкатенированной строки: {np.mean(token_length)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "id": "5810397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь после разбиения на чанки, на каждый чанк надо навесить эмбединг, чтобы положить получившиеся вектора в векторную БД\n",
    "# Подгружаем bi-encoder \n",
    "def get_bi_encoder(bi_encoder_name):\n",
    "    raw_model = Transformer(model_name_or_path=f'{bi_encoder_name}')\n",
    "\n",
    "    # Вытаскиваем размер векторов\n",
    "    bi_encoder_dim = raw_model.get_word_embedding_dimension()\n",
    "    \n",
    "    pooling_model = Pooling(\n",
    "        bi_encoder_dim,\n",
    "        pooling_mode_cls_token = False,\n",
    "        pooling_mode_mean_tokens = True\n",
    "    )\n",
    "    bi_encoder = SentenceTransformer(\n",
    "        modules = [raw_model, pooling_model]\n",
    "    )\n",
    "    \n",
    "    return bi_encoder, bi_encoder_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "id": "9f919122",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_encoder, bi_encoder_dim = get_bi_encoder('cointegrated/rubert-tiny2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "id": "1efde685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем из строки вектор\n",
    "def str_to_vec(bi_encoder, text):\n",
    "    embeddings = bi_encoder.encode(\n",
    "        text,\n",
    "        convert_to_tensor = True\n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a3836",
   "metadata": {},
   "source": [
    "# Непосредственно подходим к созданию векторной БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "id": "474e74a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLL_NAME = 'znanie_hackathon_db'\n",
    "SEP = ' '\n",
    "CHUNK_SIZE = 50\n",
    "CHUNK_OVERLAP = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "id": "6ce3d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем подключение к векторной БД\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://3bff1843-f3d9-4163-9662-c51ae29efadb.europe-west3-0.gcp.cloud.qdrant.io:6333\", \n",
    "    api_key=\"vDtHoKJfQgdmmw9RzjEcaJjIsRIlywXo79tE65enlw2WIywzwHw-dA\",\n",
    "    timeout=240\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "id": "e7c26684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Помещаем чанки и доп. информаицю в векторую БД\n",
    "def save_chunks(bi_encoder, chunks):\n",
    "    # Конвертируем чанки в векитора\n",
    "    chunk_embeddings = str_to_vec(bi_encoder, chunks)\n",
    "\n",
    "    # Создаем объект(ы) для БД\n",
    "    points = []\n",
    "    for i in range(len(chunk_embeddings)):\n",
    "        point = PointStruct(\n",
    "            id=str(uuid.uuid4()), # генерируем GUID\n",
    "            vector = chunk_embeddings[i].tolist(),\n",
    "            payload={'chunk': chunks[i]}\n",
    "        )\n",
    "        points.append(point)\n",
    "    \n",
    "    # Сохраняем вектора в БД\n",
    "    operation_info = qdrant_client.upsert(\n",
    "        collection_name = COLL_NAME,\n",
    "        wait = True,\n",
    "        points = points\n",
    "    )\n",
    "    \n",
    "    return operation_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "id": "f5af3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_vecdb(text, bi_encoder, vec_size, sep, chunk_size, chunk_overlap):    \n",
    "    # Удаляем и заново создаем коллекцию\n",
    "    qdrant_client.delete_collection(collection_name=COLL_NAME)\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name = COLL_NAME,\n",
    "        vectors_config = VectorParams(size=vec_size, distance=Distance.COSINE), # size=312 (rubert-tiny2)\n",
    "    )\n",
    "    \n",
    "\n",
    "    # делим на чанки ...\n",
    "    chunks = text_to_chunks(text, sep, chunk_size, chunk_overlap)\n",
    "    # помещаем чанки в векторную БД\n",
    "    operation_status = save_chunks(bi_encoder, chunks)\n",
    "    \n",
    "    return operation_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "id": "92714ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 28.8 s\n",
      "Wall time: 23.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 1026,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "texts_to_vecdb(merged_string_PAE, bi_encoder, bi_encoder_dim, SEP, CHUNK_SIZE, CHUNK_OVERLAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af52861",
   "metadata": {},
   "source": [
    "# Поиск векторов по косинусной близости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "360c241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_search(bi_encoder, query, n_top_cos):\n",
    "    # Кодируем запрос в вектор\n",
    "    query_emb = str_to_vec(bi_encoder, query).tolist()\n",
    "\n",
    "    # Поиск в БД\n",
    "    search_result = qdrant_client.search(\n",
    "        collection_name = COLL_NAME,\n",
    "        query_vector = query_emb,\n",
    "        limit = n_top_cos,\n",
    "        with_vectors = False\n",
    "    )\n",
    "    \n",
    "    top_chunks = [[x.payload['chunk'], x.score] for x in search_result]\n",
    "    \n",
    "    return top_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f8990",
   "metadata": {},
   "source": [
    "# Последняя идея - обучить на дополнительных текстовых фичах градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "3c9e3e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text', 'agitation', 'emotions', 'politics', 'prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "31b71576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполним пустые поля колонок фиктивным словом EMPTY\n",
    "data['agitation'] = data['agitation'].apply(lambda x: 'EMPTY' if len(x) == 0 else x)\n",
    "data['emotions'] = data['emotions'].apply(lambda x: 'EMPTY' if len(x) == 0 else x)\n",
    "data['politics'] = data['politics'].apply(lambda x: 'EMPTY' if len(x) == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "08671460",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['prediction']), \n",
    "                                                    data['prediction'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "62e1aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "train_features = model_tfidf.fit_transform(X_train[\"text\"].astype(str) + \" \" + X_train[\"agitation\"].astype(str) + \" \" + X_train[\"emotions\"].astype(str) + \" \" + X_train[\"politics\"].astype(str))\n",
    "test_features = model_tfidf.transform(X_test[\"text\"].astype(str) + \" \" + X_test[\"agitation\"].astype(str) + \" \" + X_test[\"emotions\"].astype(str) + \" \" + X_test[\"politics\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "7f2b6dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<363x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 49934 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "4fbad90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(\n",
    "    train_features,\n",
    "    y_train\n",
    ")\n",
    "\n",
    "test_pool = Pool(\n",
    "    test_features,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "id": "09927a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_catboost(trial):\n",
    "\n",
    "    params = {\n",
    "         'iterations': trial.suggest_int('iterations', 500, 2000, step=100),\n",
    "         'depth': trial.suggest_int('depth', 3, 7),\n",
    "         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1 , step=0.01),\n",
    "         'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.2, 0.9),\n",
    "         #'auto_class_weights': 'Balanced',\n",
    "         'eval_metric': \"F1\",\n",
    "         'loss_function': 'Logloss',\n",
    "         'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-2, 1,log=True),\n",
    "         'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 1.0),\n",
    "         'random_seed': 42\n",
    "    }\n",
    "\n",
    "\n",
    "    clf_catboost = CatBoostClassifier(**params)\n",
    "    clf_catboost.fit(train_pool,\n",
    "                      eval_set = test_pool, plot=False, verbose=False,\n",
    "                    early_stopping_rounds=100)\n",
    " \n",
    "    return recall_score(y_test, clf_catboost.predict(test_features), pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "id": "209b4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_catboost = optuna.create_study(study_name='catboost-seed42',\n",
    "                                direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "id": "935e08e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340fc8f77ef946b8b0d9441fa5cc343e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_catboost.optimize(objective_catboost, n_trials=100,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "id": "ce139ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 1600,\n",
       " 'depth': 4,\n",
       " 'learning_rate': 0.09,\n",
       " 'scale_pos_weight': 0.2324232236144656,\n",
       " 'l2_leaf_reg': 0.06833908762823766,\n",
       " 'colsample_bylevel': 0.9076865755180072}"
      ]
     },
     "execution_count": 1036,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_catboost.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "id": "6b53af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier(**study_catboost.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "id": "79c314f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x228d5721b90>"
      ]
     },
     "execution_count": 1038,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_pool, eval_set=test_pool, plot=False, verbose=False, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "id": "d5b94e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 1046,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "id": "9edc9abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall для класса 0: 0.828125\n",
      "Precision для класса 0: 0.6309523809523809\n",
      "F1-score: 0.8901134827526775\n"
     ]
    }
   ],
   "source": [
    "recall_0 = recall_score(y_test, preds, pos_label=0)\n",
    "precision_score_0 = precision_score(y_test, preds, pos_label=0)\n",
    "f1_score_value = f1_score(y_test, preds.astype(int), average='weighted')\n",
    "\n",
    "print(f\"Recall для класса 0: {recall_0}\")\n",
    "print(f\"Precision для класса 0: {precision_score_0}\")\n",
    "print(f\"F1-score: {f1_score_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e33e143",
   "metadata": {},
   "source": [
    "# Обучение ruBERT-tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "id": "3f75867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    'neutral': 1,\n",
    "    'not_neutral': 0\n",
    "}\n",
    "\n",
    "id2label = {\n",
    "    1: 'neutral',\n",
    "    0: 'not_neutral'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "id": "41b8ad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"cointegrated/rubert-tiny\", num_labels=len(id2label.keys()), id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "id": "264a8953",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list_of_dicts = []\n",
    "for idx, row in data.iterrows():\n",
    "    text = row['text']\n",
    "    label = row['prediction']\n",
    "    data_list_of_dicts.append({'text': str(text), 'label': label})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "dceedbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1813"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "9f35c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "def token(text):\n",
    "    return tokenizer(text['text'], padding=True, truncation=True, max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "8ad29ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/413 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "shuffle(data_list_of_dicts)\n",
    "train = data_list_of_dicts[:1400]\n",
    "test = data_list_of_dicts[1400:]\n",
    "train = Dataset.from_pandas(pd.DataFrame(data=train))\n",
    "test = Dataset.from_pandas(pd.DataFrame(data=test))\n",
    "tokenized_train = train.map(token, batched=True)\n",
    "tokenized_test = test.map(token, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "75a4321f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 413\n",
       "})"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "id": "ad64b7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    # Вычисляем взвешенную F1\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    recall = recall_score(labels, predictions, pos_label=0)\n",
    "    return {'f1': f1, 'recall': recall}  # Возвращаем словарь с метрикой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "a603ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"akra_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=7,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=weighted_loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "b13bc826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='616' max='616' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [616/616 1:04:21, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.393821</td>\n",
       "      <td>0.236533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.337360</td>\n",
       "      <td>0.226946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.332532</td>\n",
       "      <td>0.246556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.316627</td>\n",
       "      <td>0.201663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317326</td>\n",
       "      <td>0.178307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.348700</td>\n",
       "      <td>0.314068</td>\n",
       "      <td>0.198062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.348700</td>\n",
       "      <td>0.313896</td>\n",
       "      <td>0.195288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=616, training_loss=0.3357907332383193, metrics={'train_runtime': 3866.6681, 'train_samples_per_second': 2.534, 'train_steps_per_second': 0.159, 'total_flos': 72267228364800.0, 'train_loss': 0.3357907332383193, 'epoch': 7.0})"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "b956bb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ruBERT_tiny_model_2.pickle', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "38c6a98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "id": "d3abd45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predictions.predictions.argmax(axis=1)\n",
    "true_labels = tokenized_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "55d9aec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.903054448871182"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(predicted_labels, true_labels, average='weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
